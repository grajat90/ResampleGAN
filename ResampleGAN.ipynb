{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResampleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ef15f820ef845dcbd12d781aff69be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b112bf5788d4d70a526cfd655b2eba8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8129cd67dbc542c9a97953831c99b7f6",
              "IPY_MODEL_7d1bca08dee2419ea42851cd5fee4646"
            ]
          }
        },
        "3b112bf5788d4d70a526cfd655b2eba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8129cd67dbc542c9a97953831c99b7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8852963127146ff991e7d8538849946",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23ffe577a95f4bfebd23120a9a3dbe26"
          }
        },
        "7d1bca08dee2419ea42851cd5fee4646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18ed2ab2b32449fca7a71625180fd168",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/800 [01:35&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d4a6eddb86e46329cd30b9584739226"
          }
        },
        "d8852963127146ff991e7d8538849946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23ffe577a95f4bfebd23120a9a3dbe26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18ed2ab2b32449fca7a71625180fd168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d4a6eddb86e46329cd30b9584739226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGXpPjeAQ4M9"
      },
      "source": [
        "# MAIN JUPYTER NOTEBOOK FOR MINOR PROJECT\n",
        "1. Use tensorflow <b>2.3</b> for prototyping\n",
        "2. Use this link to refer to [docs](https://www.tensorflow.org/api_docs/python/tf/all_symbols) and this to refer to [tutorials](https://www.tensorflow.org/tutorials).\n",
        "3. Our github repo is [here](https://github.com/grajat90/ResampleGAN).\n",
        "\n",
        "\n",
        "## For quick reference:\n",
        "\n",
        "### Original Networks in SRGAN paper:\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*T_vCYUgD8UygdMWlgV3ciw.png\" width = '60%' />\n",
        "\n",
        "</center>\n",
        "\n",
        "### Our network (change as needed):\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/ebd11f6dea8996adcb01132ccd0526e971f4b12b/68747470733a2f2f696d6775722e636f6d2f4a6a7a555958732e6a7067\" width = '60%'/>\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/07e22e49a908fe6e243468d335a702854260db56/68747470733a2f2f696d6775722e636f6d2f316973696737432e6a7067\" width = '60%' />\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25MgJqVlD8h"
      },
      "source": [
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.activations import tanh\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Add, PReLU, LeakyReLU, UpSampling2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "from tensorflow.python.keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjaqSDbm4V_r"
      },
      "source": [
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# # This is the TPU initialization code that has to be at the beginning.\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh2w3fBa8wSZ",
        "outputId": "bdea31a9-dcb7-468e-fa41-d56a9f2968bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(ds_train, ds_validation), info = tfds.load(\n",
        "    'div2k/bicubic_x4',\n",
        "    split=['train', 'validation'],\n",
        "    shuffle_files=True,\n",
        "    with_info = True\n",
        ")\n",
        "print(len(ds_train))\n",
        "ds_train=ds_train.batch(1)\n",
        "ds_validation = ds_validation.batch(1)\n",
        "#ds_validation=ds_validation.as_numpy_iterator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWkSVU3MwAIB",
        "outputId": "7697b1b1-847c-4c35-ccf7-b90c58ab5e96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.compat.v1.RunOptions(\n",
        "    report_tensor_allocations_upon_oom=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "report_tensor_allocations_upon_oom: true"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14tMYRialpDi"
      },
      "source": [
        "def generator(momentum=0.8):\n",
        "  lr_in = tf.keras.Input(shape=(None,None,3))\n",
        "  hr_out = Conv2DTranspose(filters = 64, kernel_size = (9,9), padding='SAME')(lr_in)  #k9n64s1\n",
        "  hr_out = B = PReLU(shared_axes=[1, 2])(hr_out)\n",
        "  for i in range(5):\n",
        "    B_internal = B\n",
        "    for j in range(2):\n",
        "      B_internal = Conv2DTranspose(filters = 64, kernel_size = (3,3), padding='SAME')(B_internal) #k3n64s1\n",
        "      B_internal = BatchNormalization(momentum=momentum)(B_internal)\n",
        "      B_internal = PReLU(shared_axes=[1, 2])(B_internal)\n",
        "    B = Add()([B, B_internal])\n",
        "  B = Conv2DTranspose(filters = 64, kernel_size = (3,3), padding='SAME')(B) #k3n64s1\n",
        "  B = BatchNormalization(momentum=momentum)(B)\n",
        "  hr_out = Add()([hr_out, B])\n",
        "  for i in range(2):\n",
        "    hr_out = Conv2DTranspose(filters = 256, kernel_size = (3,3), padding = \"SAME\")(hr_out) #k3n256s1\n",
        "    hr_out = UpSampling2D(size=2)(hr_out)\n",
        "    hr_out = PReLU(shared_axes=[1, 2])(hr_out)\n",
        "\n",
        "  hr_out = Conv2DTranspose(filters = 3, kernel_size = (9,9), padding = \"SAME\")(hr_out) #k9n3s1\n",
        "  # hr_out = tanh(hr_out)\n",
        "  return Model(lr_in, hr_out, name=\"GAN_GEN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOikwdgjOPGw"
      },
      "source": [
        "def discriminator(momentum=0.8):\n",
        "  img_in = tf.keras.Input(shape = (None,None,3))\n",
        "  #k3n64s1\n",
        "  pred = Conv2D(filters = 64, kernel_size=(3,3), padding = \"SAME\")(img_in)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n64s2\n",
        "  pred = Conv2D(filters=64, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "  \n",
        "  #k3n128s1\n",
        "  pred = Conv2D(filters=128, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "  \n",
        "  #k3n128s2\n",
        "  pred = Conv2D(filters=128, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n256s1\n",
        "  pred = Conv2D(filters=256, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n256s2\n",
        "  pred = Conv2D(filters=256, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n512s1\n",
        "  pred = Conv2D(filters=512, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n512s2\n",
        "  pred = Conv2D(filters=512, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #avoiding dense layer for dimensional invariance\n",
        "  pred = Conv2D(filters=1, kernel_size=3, padding=\"SAME\")(pred)\n",
        "\n",
        "  return Model(img_in, pred, name=\"GAN_DISC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVO5obQJQkBt"
      },
      "source": [
        "gen_model = generator(0.65)\n",
        "disc_model = discriminator(0.65)\n",
        "gen_optimizer = Adam(learning_rate=1e-4)\n",
        "disc_optimizer = Adam(learning_rate=1e-4)\n",
        "def vgg():\n",
        "    _ = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "    return Model(_.input, _.layers[20].output)\n",
        "vgg_model = vgg()\n",
        "\n",
        "@tf.function\n",
        "def vgg_loss(true_image, fake_image):\n",
        "  true_image = vgg19_preprocess(true_image)\n",
        "  fake_image = vgg19_preprocess(fake_image)\n",
        "  true_features = vgg_model(true_image)\n",
        "  fake_features = vgg_model(fake_image)\n",
        "  mseError = tf.keras.losses.mean_squared_error(true_features, fake_features)\n",
        "  mseError = tf.math.reduce_mean(mseError)\n",
        "  return mseError\n",
        "\n",
        "@tf.function\n",
        "def discLoss(true_output, fake_output):\n",
        "  disc_fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
        "  disc_true_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(true_output), true_output)\n",
        "  return disc_fake_loss + disc_true_loss\n",
        "\n",
        "@tf.function\n",
        "def genLoss(fake_output):\n",
        "  gen_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(fake_output), fake_output)\n",
        "  gen_loss = tf.math.reduce_mean(gen_loss)\n",
        "  return gen_loss\n",
        "\n",
        "@tf.function\n",
        "def train_step(lr, hr):\n",
        "  with tf.device('/gpu:0'):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      lr = tf.cast(lr, tf.float32)\n",
        "      hr = tf.cast(hr, tf.float32)\n",
        "      hr_generated = gen_model(lr, training=True)\n",
        "      fake_output = disc_model(hr_generated, training=True)\n",
        "      real_output = disc_model(hr, training = True)\n",
        "      content_loss = vgg_loss(hr, hr_generated)\n",
        "      disc_loss = discLoss(real_output, fake_output)\n",
        "      gen_loss = content_loss + genLoss(fake_output)*1e-3\n",
        "\n",
        "    gen_gradients = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
        "    disc_gradients = disc_tape.gradient(disc_loss, disc_model.trainable_variables)\n",
        "    gen_optimizer.apply_gradients(zip(gen_gradients, gen_model.trainable_variables))\n",
        "    disc_optimizer.apply_gradients(zip(disc_gradients, disc_model.trainable_variables))\n",
        "\n",
        "  return disc_loss, gen_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOtIeaYvWWQC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGP8fvC0h9o5",
        "outputId": "2e521abf-eddf-4d86-b97a-fa31541fd0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "6ef15f820ef845dcbd12d781aff69be3",
            "3b112bf5788d4d70a526cfd655b2eba8",
            "8129cd67dbc542c9a97953831c99b7f6",
            "7d1bca08dee2419ea42851cd5fee4646",
            "d8852963127146ff991e7d8538849946",
            "23ffe577a95f4bfebd23120a9a3dbe26",
            "18ed2ab2b32449fca7a71625180fd168",
            "6d4a6eddb86e46329cd30b9584739226"
          ]
        }
      },
      "source": [
        "\n",
        "def train(epochs):\n",
        "  epoch = 0\n",
        "  for idx, elem in enumerate(tqdm(ds_train)):\n",
        "    epoch += 1\n",
        "    hr = tf.cast(elem['hr'], tf.float32)\n",
        "    lr = tf.cast(elem['lr'], tf.float32)\n",
        "    hr = hr/255.0\n",
        "    lr = lr/255.0\n",
        "    d_loss, g_loss = train_step(lr, hr)\n",
        "    print(f\"{d_loss} - Discriminator Loss \\n {g_loss} - Generator loss\\n\\n\")\n",
        "    if(epoch==1):\n",
        "      break\n",
        "  # for epoch in range(epochs):\n",
        "  #   print(\"Iter {}/{}, DIV2K BICUBIC 4X\".format(epoch, epochs))\n",
        "  #   for data_next in tqdm(ds_train):\n",
        "  #     hr = [data_next['hr']/255.0]\n",
        "  #     lr = [data_next['lr']/255.0]\n",
        "  #     d_loss, g_loss = train_step(lr, hr)\n",
        "  return 0\n",
        "        \n",
        "\n",
        "train(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ef15f820ef845dcbd12d781aff69be3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=800.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f03b91f76823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-f03b91f76823>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mhr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{d_loss} - Discriminator Loss \\n {g_loss} - Generator loss\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,666,1020,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node GAN_GEN/p_re_lu_66/Relu (defined at <ipython-input-21-84aab1eb7993>:38) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_step_45259]\n\nFunction call stack:\ntrain_step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19R-jCwadriI"
      },
      "source": [
        "ds_v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQm7yfQsQyZ8"
      },
      "source": [
        ""
      ]
    }
  ]
}