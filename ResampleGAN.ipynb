{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResampleGAN_2-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGXpPjeAQ4M9"
      },
      "source": [
        "# MAIN JUPYTER NOTEBOOK FOR MINOR PROJECT\n",
        "1. Use tensorflow <b>2.3</b> for prototyping\n",
        "2. Use this link to refer to [docs](https://www.tensorflow.org/api_docs/python/tf/all_symbols) and this to refer to [tutorials](https://www.tensorflow.org/tutorials).\n",
        "3. Our github repo is [here](https://github.com/grajat90/ResampleGAN).\n",
        "\n",
        "\n",
        "## For quick reference:\n",
        "\n",
        "### Original Networks in SRGAN paper:\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*T_vCYUgD8UygdMWlgV3ciw.png\" width = '60%' />\n",
        "\n",
        "</center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25MgJqVlD8h"
      },
      "source": [
        "!pip install tensorflow-gpu==2.3.1\n",
        "import os\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import auth, drive\n",
        "from PIL import Image\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.activations import tanh\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Add, PReLU, LeakyReLU, UpSampling2D, GlobalAveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "from tensorflow.python.keras.applications.vgg19 import VGG19, preprocess_input as vgg19_preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh2w3fBa8wSZ"
      },
      "source": [
        "(ds_train, ds_validation), info = tfds.load(\n",
        "    'div2k/bicubic_x4',\n",
        "    split=['train', 'validation'],\n",
        "    shuffle_files=True,\n",
        "    with_info = True,\n",
        "    try_gcs = True,\n",
        "    data_dir = './dataset'\n",
        ")\n",
        "\n",
        "print(len(ds_validation))\n",
        "ds_train=ds_train.prefetch(512)\n",
        "ds_validation = ds_validation.prefetch(512)\n",
        "#ds_validation=ds_validation.as_numpy_iterator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWkSVU3MwAIB"
      },
      "source": [
        "tf.compat.v1.RunOptions(\n",
        "    report_tensor_allocations_upon_oom=True\n",
        ")\n",
        "#tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14tMYRialpDi"
      },
      "source": [
        "def generator(momentum=0.8):\n",
        "  lr_in = tf.keras.Input(shape=(None,None,3))\n",
        "  hr_out = Conv2DTranspose(filters = 64, kernel_size = (9,9), padding='SAME')(lr_in)  #k9n64s1\n",
        "  hr_out = B = PReLU(shared_axes=[1, 2])(hr_out)\n",
        "  for i in range(5):\n",
        "    B_internal = B\n",
        "    for j in range(2):\n",
        "      B_internal = Conv2DTranspose(filters = 64, kernel_size = (3,3), padding='SAME')(B_internal) #k3n64s1\n",
        "      B_internal = BatchNormalization(momentum=momentum)(B_internal)\n",
        "      B_internal = PReLU(shared_axes=[1, 2])(B_internal)\n",
        "    B = Add()([B, B_internal])\n",
        "  B = Conv2DTranspose(filters = 64, kernel_size = (3,3), padding='SAME')(B) #k3n64s1\n",
        "  B = BatchNormalization(momentum=momentum)(B)\n",
        "  hr_out = Add()([hr_out, B])\n",
        "  for i in range(2):\n",
        "    hr_out = Conv2DTranspose(filters = 256, kernel_size = (3,3), padding = \"SAME\")(hr_out) #k3n256s1\n",
        "    hr_out = UpSampling2D(size=2)(hr_out)\n",
        "    hr_out = PReLU(shared_axes=[1, 2])(hr_out)\n",
        "\n",
        "  hr_out = Conv2DTranspose(filters = 3, kernel_size = (9,9), padding = \"SAME\")(hr_out) #k9n3s1\n",
        "  # hr_out = tanh(hr_out)\n",
        "  return Model(lr_in, hr_out, name=\"GAN_GEN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOikwdgjOPGw"
      },
      "source": [
        "def discriminator(momentum=0.8):\n",
        "  img_in = tf.keras.Input(shape = (None,None,3))\n",
        "  #k3n64s1\n",
        "  pred = Conv2D(filters = 64, kernel_size=(3,3), padding = \"SAME\")(img_in)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n64s2\n",
        "  pred = Conv2D(filters=64, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "  \n",
        "  #k3n128s1\n",
        "  pred = Conv2D(filters=128, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "  \n",
        "  #k3n128s2\n",
        "  pred = Conv2D(filters=128, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n256s1\n",
        "  pred = Conv2D(filters=256, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n256s2\n",
        "  pred = Conv2D(filters=256, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n512s1\n",
        "  pred = Conv2D(filters=512, kernel_size=(3,3), strides=1, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #k3n512s2\n",
        "  pred = Conv2D(filters=512, kernel_size=(3,3), strides=2, padding=\"VALID\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "\n",
        "  #avoiding dense layer for dimensional invariance k3n1s1\n",
        "  pred = Conv2D(filters=1, kernel_size=3, padding=\"SAME\")(pred)\n",
        "  pred = BatchNormalization(momentum=momentum)(pred)\n",
        "  pred = LeakyReLU()(pred)\n",
        "  #gap\n",
        "  pred = GlobalAveragePooling2D()(pred)\n",
        "\n",
        "  \n",
        "  #with dense\n",
        "\n",
        "  pred = Dense(1, activation=\"sigmoid\")(pred)\n",
        "\n",
        "  return Model(img_in, pred, name=\"GAN_DISC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVO5obQJQkBt"
      },
      "source": [
        "# with strategy.scope():\n",
        "gen_model = generator(0.5)\n",
        "disc_model = discriminator(0.5)\n",
        "gen_optimizer = Adam(learning_rate=1e-6)\n",
        "disc_optimizer = Adam(learning_rate=1e-6)\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "def vgg():\n",
        "    _ = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "    return Model(_.input, _.layers[20].output)\n",
        "vgg_model = vgg()\n",
        "\n",
        "\n",
        "def vgg_loss(true_image, fake_image):\n",
        "  true_image = vgg19_preprocess(true_image)\n",
        "  fake_image = vgg19_preprocess(fake_image)\n",
        "  true_features = vgg_model(true_image)\n",
        "  fake_features = vgg_model(fake_image)\n",
        "  mseError = mse(true_features, fake_features)\n",
        "  return mseError\n",
        "\n",
        "\n",
        "def discLoss(true_output, fake_output):\n",
        "  disc_fake_loss = bce(tf.zeros_like(fake_output), fake_output)\n",
        "  disc_true_loss = bce(tf.ones_like(true_output), true_output)\n",
        "  return disc_fake_loss + disc_true_loss\n",
        "\n",
        "\n",
        "def genLoss(fake_output):\n",
        "  gen_loss = bce(tf.ones_like(fake_output), fake_output)\n",
        "  return gen_loss\n",
        "\n",
        "# @tf.function\n",
        "def train_step(lr, hr):\n",
        "  #with tf.device('/gpu:0'):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    lr = tf.dtypes.saturate_cast(lr, tf.float32)\n",
        "    hr = tf.dtypes.saturate_cast(hr, tf.float32)\n",
        "    hr_generated = gen_model(lr, training=True)\n",
        "    fake_output = disc_model(hr_generated, training=True)\n",
        "    real_output = disc_model(hr, training = True)\n",
        "    content_loss = vgg_loss(hr, hr_generated)\n",
        "    disc_loss = discLoss(real_output, fake_output)\n",
        "    color_loss = mse(hr,hr_generated)\n",
        "    gen_loss = content_loss + genLoss(fake_output)*1e-3 + color_loss*0.5\n",
        "\n",
        "  gen_gradients = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
        "  disc_gradients = disc_tape.gradient(disc_loss, disc_model.trainable_variables)\n",
        "  gen_optimizer.apply_gradients(zip(gen_gradients, gen_model.trainable_variables))\n",
        "  disc_optimizer.apply_gradients(zip(disc_gradients, disc_model.trainable_variables))\n",
        "\n",
        "  return disc_loss, gen_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9qxLg3uSNsq"
      },
      "source": [
        "try:\n",
        "    load_gen = gen_model.load_weights(\"./checkpoint/GEN\")\n",
        "    load_disc = disc_model.load_weights(\"./checkpoint/DISC\")\n",
        "    load_gen.assert_consumed()\n",
        "    load_gen.assert_consumed()\n",
        "except:\n",
        "  print(\"Cannot Load model weight - either running for first time or data/path in not proper format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzFCGRnlOgQI"
      },
      "source": [
        "def saveimg(epoch):\n",
        "  kid_hr = img.imread(\"./img.jpg\")\n",
        "  shp = [kid_hr.shape[0]//4,kid_hr.shape[1]//4]\n",
        "  kid_lr = tf.image.resize(kid_hr, shp, method=\"bicubic\")\n",
        "  kid_lr = tf.dtypes.saturate_cast([kid_lr], tf.float32)\n",
        "  kid_lr = kid_lr/255.0\n",
        "  hr_gen = gen_model(kid_lr, training=False)[0]\n",
        "  hr_gen = hr_gen*255.0\n",
        "  hr_gen = tf.dtypes.saturate_cast(hr_gen, tf.uint8)\n",
        "  hr_gen = hr_gen.numpy()\n",
        "  hr_gen = Image.fromarray(hr_gen)\n",
        "  imgfile = \"./it-{}.jpg\".format(epoch)\n",
        "  hr_gen.save(imgfile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WibSV2HUpTAO"
      },
      "source": [
        "data = {}\n",
        "try:\n",
        "  with open('./epoch-data.json', 'r') as fp:\n",
        "    data = json.load(fp)\n",
        "    data = dict([int(key), value] for key, value in data.items())  \n",
        "except:\n",
        "  pass\n",
        "def epochsave(epoch, g_err, d_err):\n",
        "  data[int(epoch)] = {'g_err': str(g_err), 'd_err': str(d_err)}\n",
        "  with open('./epoch-data.json', 'w') as fp:\n",
        "    json.dump(data, fp, sort_keys=True, indent=\"\")\n",
        "    fp.close()\n",
        "  return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaGcL2xJJVGw"
      },
      "source": [
        "def rcrop(img, rxseed, ryseed):\n",
        "  (shapex,shapey) = img.shape[:2]\n",
        "  # sizex = midx//6\n",
        "  # sizey = midy//6\n",
        "  sizex = 700+rxseed\n",
        "  sizey = 700+ryseed\n",
        "  xstart = random.randint(10,shapex-(sizex+10))\n",
        "  ystart = random.randint(10,shapey-(sizey+10))\n",
        "  return (img[xstart:xstart+sizex, ystart:ystart+sizey, :], [sizex, sizey])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGP8fvC0h9o5"
      },
      "source": [
        "#batched\n",
        "possible = [x for x in range(-50,51) if x%4==0]\n",
        "\n",
        "\n",
        "def train(epochs, batch_size, skip_epochs):\n",
        "  g_loss = None\n",
        "  d_loss = None\n",
        "  try:\n",
        "    load_gen = gen_model.load_weights(\"./checkpoint/GEN\")\n",
        "    load_disc = disc_model.load_weights(\"./checkpoint/DISC\")\n",
        "    load_gen.assert_consumed()\n",
        "    load_gen.assert_consumed()\n",
        "  except:\n",
        "    print(\"Cannot Load model weight - either running for first time or data/path in not proper format\")\n",
        "  for epoch in tqdm(range(1,epochs+1)):\n",
        "    if epoch<=skip_epochs:\n",
        "      continue\n",
        "    print(f\"========================================\\nEpoch - {epoch}\")\n",
        "    gLoss = 0\n",
        "    dLoss = 0\n",
        "    lr_batch = []\n",
        "    hr_batch = []\n",
        "    rxseed = random.choice(possible)\n",
        "    ryseed = random.choice(possible)\n",
        "    for idx, elem in enumerate(tqdm(ds_train)):\n",
        "      hr = tf.dtypes.saturate_cast(elem['hr'], tf.float32)\n",
        "      (hr, shape) = rcrop(hr, rxseed, ryseed)\n",
        "      # lr = tf.cast(elem['lr'], tf.float32)\n",
        "      # lr = rcrop(lr)\n",
        "      shape = [x//4 for x in shape if x%4 == 0]\n",
        "      lr = tf.image.resize(hr, shape, method=\"bicubic\")\n",
        "      hr = hr/255.0\n",
        "      lr = lr/255.0\n",
        "      lr_batch.append(lr)\n",
        "      hr_batch.append(hr)\n",
        "      if((idx+1)%batch_size==0):\n",
        "        d_loss, g_loss = train_step(lr_batch, hr_batch)\n",
        "        gLoss += g_loss\n",
        "        dLoss += d_loss\n",
        "        lr_batch = []\n",
        "        hr_batch = []\n",
        "        rxseed = random.choice(possible)\n",
        "        ryseed = random.choice(possible)\n",
        "      # d_loss, g_loss = strategy.run(train_step, args=(lr, hr))\n",
        "    if(not ((idx+1)%batch_size==0)):\n",
        "        d_loss, g_loss = train_step(lr_batch, hr_batch)\n",
        "        gLoss += g_loss\n",
        "        dLoss += d_loss\n",
        "        lr_batch = []\n",
        "        hr_batch = []\n",
        "    print(f\"{dLoss/800} - Discriminator Loss \\n {gLoss/800} - Generator loss\\n========================================\\n\")\n",
        "    gen_model.save_weights(\"./checkoint/GEN\")\n",
        "    disc_model.save_weights(\"./checkpoint/DISC\")\n",
        "    epochsave(epoch, (gLoss/800).numpy(), (dLoss/800).numpy())\n",
        "    if((epoch)%50==0):\n",
        "      saveimg(epoch)\n",
        "  # for epoch in range(epochs):\n",
        "  #   print(\"Iter {}/{}, DIV2K BICUBIC 4X\".format(epoch, epochs))\n",
        "  #   for data_next in tqdm(ds_train):\n",
        "  #     hr = [data_next['hr']/255.0]\n",
        "  #     lr = [data_next['lr']/255.0]\n",
        "  #     d_loss, g_loss = train_step(lr, hr)\n",
        "      \n",
        "#cnn-gap-dense\n",
        "try:\n",
        "  skip_epochs = int(max(k for k,v in data.items()))\n",
        "except:\n",
        "  skip_epochs = 0\n",
        "train(epochs=2500, batch_size=5, skip_epochs=skip_epochs) #593"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNBB71LQWOAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}